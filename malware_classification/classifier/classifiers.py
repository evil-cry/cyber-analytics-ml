# AI Usage Statement
# Tools Used: GitHub Copilot

# Usage: Code completion for transforming csv into a dict with pandas
# Verification: A manually written test that confirms the dict is exactly the same as if reding with csv lib

# Usage: Brainstorming solutions for memory usage issues
# Verification: I ended up being the one who came up with and implemented the final idea. Copilot only suggested using xxhash instead of built-in 

# Prohibited Use Compliance: Confirmed

import zipfile
import xxhash
import torch
import pickle
import numpy as np
import pandas as pd

class Storage:
    '''
    Class for storing data
    '''
    def __init__(self, feature_vectors_file: str, families_file: str):
        self.feature_vectors_file = feature_vectors_file
        self.families_file = families_file

        # initiate lazy load and provide a layer of separation
        self.possible_features = self._possible_features()
        self.families = self._families()
        self.possible_families = set(self.families.values())

        self.samples = self._samples()

        self.feature_list, self.label_list = self._ordered_lists()

        self.test_collision_rate()
        print(f'Benign Samples: {self.label_list.count(-1)}')
        print(f'Malware Samples: {self.label_list.count(1)}')

    def save(self, path):
        with open(path, 'wb') as f:
            pickle.dump(self.__dict__, f)

    @classmethod
    def load(cls, path):
        storage = cls.__new__(cls)  # Create instance without calling __init__
        with open(path, 'rb') as f:
            storage.__dict__ = pickle.load(f)
        return storage
        
    def _samples(self):
        '''
        Returns a dictionary {sample_hash:vector} (str:dict)
        '''
        samples = {}

        # TODO REMOVE THIS WHEN DONE TESTING
        #i = 100

        with zipfile.ZipFile(self.feature_vectors_file, 'r') as zip:
            for feature_file in zip.namelist():
                
                # ignore the zip itself
                if feature_file == 'feature_vectors/':
                    continue

                sample = Sample(feature_file[len('/feature_vectors/'):], self.possible_features) # strip the path from the hash

                with zip.open(feature_file) as ff:
                    content = ff.read()
                    features = content.strip().split(b'\n')

                    sample.add_features(features)

                if sample.hash in self.families.keys():
                    sample.family = self.families[sample.hash]
                    sample.string_label = 'malware'
                    sample.label = 1 # 1 for malware
                else:
                    sample.string_label = 'benign'
                    sample.label = -1 # -1 for benign
                
                samples[sample.hash] = sample

                #if i <= 0:
                #    break
                #i -= 1
        
        return samples

    def _possible_features(self) -> set:
        '''
        Returns a set of all possible features
        '''
        possible_features = set()

        with zipfile.ZipFile(self.feature_vectors_file, 'r') as zip:
            for feature_file in zip.namelist(): # iterate over all file names
                with zip.open(feature_file) as ff: # read the files
                    content = ff.read()
                    features = content.strip().split(b'\n') # get each line into a list

                    for feature in features:
                        if feature:
                            possible_features.add(feature.strip())
        
        return possible_features
    
    def _families(self):
        '''
        Returns a dict {sample_hash:family} (str:str)
        '''
        df = pd.read_csv(self.families_file, header=0) # use first row as a header
        return dict(zip(df['sha256'], df['family']))
    
    def _ordered_lists(self):
        # Fun fact: list comprehension is faster than loops. 
        feature_list = [sample.features.values() for sample in self.samples]
        label_list = [sample.label for sample in self.samples]
        
        return feature_list, label_list 
    
        '''
        X_list = []
        for sample_hash, sample in self.samples.items():
            vector = sample.features
            row = []
            for feature in self.possible_features:
                row.append(vector[feature])
            X_list.append(row)
        '''

    def test_collision_rate(self):
        size = len(self.possible_features)
        collisions = 0
        seen = set()
        
        for s in self.possible_features:
            h = xxhash.xxh64(s).intdigest() % size
            if h in seen:
                collisions += 1
            seen.add(h)
        
        print(f'Possible features: {size}. Collisions: {collisions}.')

class Sample:
    '''
    Class for storing samples
    '''

    def __init__(self, hash, possible_features) -> None:
        self.hash = hash
        
        # assume none of the features are present
        self.features = np.zeros(len(possible_features), dtype=np.bool)

        self.family = None
        self.string_label = None
        self.label = 0 # 0 for unknown
                    
    def add_features(self, features: list):
        for feature in features:
            if feature:
                # using dictionaries for storing features eats too much RAM and crashes
                # apparently, built-in python hash() is quite bad
                index = xxhash.xxh64(feature).intdigest() % len(self.features)
                self.features[index] = 1

class _Algorithm:
    '''
    Generic methods and constructors for ML algorithms
    '''

    def __init__(self, storage: Storage) -> None:
        self.storage = storage
        self.samples = storage.samples
        self.possible_features = storage.possible_features
        self.families = storage.families
        self.possible_families = storage.possible_families

    def train():
        raise NotImplementedError()
    
    def evaluate():
        raise NotImplementedError()

class SVM(_Algorithm):
    '''
    Support Vector Machine Algorithm
    Performs Binary Classification - benign samples are -1 and malware is +1
    '''
    def __init__(self, *args, **kwargs) -> None:
        super(SVM, self).__init__(*args, **kwargs)
        self.name = "Support Vector Machine"
        self.X, self.Y = self.prepare_data()
        self.train_model()
        self.evaluate()

    def get_tensors(self):
        '''
        Returns tuple - X_tensor, Y_tensor
        '''
    
        X_tensor = torch.tensor(self.storage.feature_list, dtype=torch.float64)
        Y_tensor = torch.tensor(self.storage.label_list, dtype=torch.float64)

        return X_tensor, Y_tensor
    
    def train(self):
        '''
        Train model utilizing Stochastic Gradient Descent with Hinge Loss
        '''
        pass

    def evaluate(self):
        '''
        Evaluate the SVM using the training data
        '''
        pass