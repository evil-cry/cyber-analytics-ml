import classifiers
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from collections import Counter
from itertools import combinations

class _MultiClassClassifier:
    '''
    Class for Multi-Class classification.\n
    '''
    def __init__(self, storage: classifiers.Storage, model: classifiers.SVM, target_classes = [], training_percentage: float = 0.8, top_N = 20, *args, **kwargs):
        self.storage = storage
        self.model = model
        self.training_percentage = training_percentage
        self.top_N = top_N
        self.classifiers_dict = {}
        self.classifiers = []

        if not target_classes:
            self.target_classes = storage.possible_families_list
        else:
            self.target_classes = target_classes

    def confusion_matrix(self):
        '''
        Creates a normalized confusion matrix.\n
        '''
        # Predict for test data
        y_true = []
        y_pred = []
        
        # Iterate through the test samples of top families
        for family in self.top_families:
            # Get test samples for this family
            test_samples = set()
            for classifiers in self.classifiers_dict.values():
                for classifier in classifiers:
                    test_samples.update(classifier.testing_samples)

            # Remove duplicates while preserving order
            # This is the most efficient way to do it that I could find
            # test_samples = list(dict.fromkeys(test_samples))
            
            for sample in test_samples:
                # True label
                y_true.append(sample.family)
                
                # Prediction using voting mechanism
                prediction = self.predict(sample)
                y_pred.append(prediction)
        
        # Create confusion matrix
        c_matrix = np.zeros((len(self.top_families), len(self.top_families)), dtype=int)
        
        # Populate confusion matrix
        for true, pred in zip(y_true, y_pred):
            if true in self.top_families:
                true_idx = self.top_families.index(true)
                pred_idx = self.top_families.index(pred) if pred in self.top_families else None
                if pred_idx is not None:
                        c_matrix[true_idx, pred_idx] += 1

        self.matrix = c_matrix

        # calculate accuracy
        accuracy = np.trace(c_matrix) / np.sum(c_matrix)

        print(f'Overall accuracy: {accuracy}')
        
        return {
            'c_matrix': c_matrix,
            'acc': accuracy
        }
        
    def present_confusion_matrix(self):
        '''
        Prints the confusion matrix for the top N families and saves a graph.
        @params: 
        - matrix: np array of the confusion matrix
        - target_classes: list of target families
        '''
        # Visualization
        plt.figure(figsize=(10, 8))
        sns.heatmap(self.matrix, 
                    annot=True, 
                    fmt='d', 
                    cmap='Blues', 
                    xticklabels=self.top_families, 
                    yticklabels=self.top_families,
                    cbar_kws={'label': 'Number of samples'})
        plt.title(f'Confusion Matrix - {self.name} Classifier')
        plt.xlabel('Predicted Label')
        plt.ylabel('True Label')
        path = f'malware_classification/graphs/confusion_matrix_{self.name}.png'
        plt.savefig(path)
        print(f'Confusion matrix \n{self.matrix} saved to {path}.')
        
class OneVsOne(_MultiClassClassifier):
    '''
    Class for One-vs-One technique.\n
    '''
    def __init__(self, *args, **kwargs):
        super(OneVsOne, self).__init__(*args, **kwargs)

        self.name = 'One-vs-One'
        self.train(**kwargs)
        self.confusion_matrix()

    def train(self,**kwargs):
        '''
        Trains the models for the One-vs-One technique.\n
        @params:\n
        \tkwargs: dictionary the hyperparameters
        '''

        if not (self.storage and self.storage.possible_families_dict):
            return None
        
        all_classes = self.storage.possible_families_dict

        # sort families by count
        local_top_families = sorted(all_classes.items(), # in all the items 
                              key=lambda x: x[1], # use count (second element) as sorting key
                              reverse=True) # descending order
        
        self.top_families  = [item[0] for item in local_top_families[:self.top_N]] # crop to top N
        print(f'Top {len(self.top_families)}families: {self.top_families}')

        # get all possible pairs
        class_pairs = list(combinations(self.top_families, 2))
        print(f'Total pairs: {len(class_pairs)}')

        # iterate over the pairs and train the models
        for class1, class2 in class_pairs:
            classifier = self.model(self.storage, class1, class2, self.training_percentage, **kwargs)
            
            if not classifier: # if there was an issue with the classifier, skip it
                continue

            # append the classifier to the list of classifiers
            if self.classifiers_dict.get(class1):
                self.classifiers_dict[class1].append(classifier)
            else:
                self.classifiers_dict[class1] = [classifier]
            if self.classifiers_dict.get(class2):
                self.classifiers_dict[class2].append(classifier)
            else:
                self.classifiers_dict[class2] = [classifier]

            self.classifiers.append(classifier)

    def predict(self, sample: classifiers.Sample) -> None:
        votes = Counter()

        # get predictions from all classifiers
        for classifier in self.classifiers:
            prediction = classifier.classify_string(sample)

            if not prediction:
                continue

            votes[prediction] += 1

        most_voted = votes.most_common(1)[0][0]
    
        return most_voted if votes[most_voted] > 1 else None

class OneVsAll(_MultiClassClassifier):
    '''
    Class for One-vs-All technique.\n
    '''

    def __init__(self, *args, **kwargs):
        super(OneVsAll, self).__init__(*args, **kwargs)

        self.name = 'One-vs-All'
        self.train(**kwargs)
        self.confusion_matrix()

    def train(self, **kwargs):
        '''
        Trains the models for the One-vs-All technique.
        '''

        if not (self.storage and self.storage.possible_families_dict):
            return None

        all_classes = self.storage.possible_families_dict
        if 'benign' in all_classes:
            all_classes.pop('benign') # do not consider benign samples

        # sort families by count
        local_top_families = sorted(all_classes.items(), # in all the items 
                              key=lambda x: x[1], # use count (second element) as sorting key
                              reverse=True)
        
        self.top_families  = [item[0] for item in local_top_families[:self.top_N]] # crop to top N
        print(f'Top families: {self.top_families}')

        # iterate over the top families and train the models
        for family in self.top_families:
            classifier = self.model(self.storage, family, None, self.training_percentage, **kwargs)

            if not classifier:
                continue

            # append the classifier to the list of classifiers
            if self.classifiers_dict.get(family):
                self.classifiers_dict[family].append(classifier)
            else:
                self.classifiers_dict[family] = [classifier]

            self.classifiers.append(classifier)

    def predict(self, sample: classifiers.Sample) -> None:
        '''
        Perform multi-class classification using One-vs-All technique.
        '''
        predictions = {}
        
        all_scores = []
        family_to_scores = {}
        
        for family, classifiers in self.classifiers_dict.items():
            scores = [classifier.evaluate(sample) for classifier in classifiers] # get raw scores specifically
            if scores:
                max_score = max(scores) # get the highest score
                all_scores.append(max_score)
                family_to_scores[family] = max_score
        
        if all_scores:
            # calculate the range to apply normalization
            min_score = min(all_scores)
            max_score = max(all_scores)
            score_range = max_score - min_score
            
            # normalize
            if score_range > 0:
                for family, score in family_to_scores.items():
                    predictions[family] = (score - min_score) / score_range
            else:
                # if all scores are the same, just copy them
                predictions = family_to_scores
        
        # choose family with highest normalized score
        if predictions:
            return max(predictions.items(), key=lambda x: x[1])[0]
        return None